# Estudo de Caso - Deploy de App com Docker e Agente de IA Para Provisionamento de Infraestrutura com IaC
#=================================================
# ARQUIVO: app/app.py
#=================================================
# Este √© o script da aplica√ß√£o para criar a interface de usu√°rio e gerenciar a intera√ß√£o com o Agente de IA.
import os
import streamlit as st
# Removendo CrewAI, Agent, Task, Crew, Process, OpenAI, dotenv, requests, json
# Se voc√™ n√£o for usar CrewAI, essas importa√ß√µes n√£o s√£o necess√°rias.
# Se voc√™ for usar requests e json para outras coisas, mantenha.
from dotenv import load_dotenv
import requests
import json

# Carrega as vari√°veis de ambiente. Essencial para o Docker.
load_dotenv()

# --- Configura√ß√£o da P√°gina do Streamlit ---
st.set_page_config(
    page_title="Data Science Academy",
    page_icon=":100:",
    layout="wide"
)

st.title("ü§ñ Gerador de Scripts Terraform com Agente de IA")
st.markdown("""
Esta ferramenta utiliza um Agente de IA especializado para converter suas descri√ß√µes de infraestrutura
em c√≥digo Terraform (HCL) pronto para uso.
""")

# --- Configura√ß√£o do Agente IA OpenRouter Gemini---
# A ideia aqui √© criar uma fun√ß√£o ou classe que encapsule a chamada ao OpenRouter
# para que o "agente" (que agora ser√° uma fun√ß√£o simples) possa us√°-la.

def call_openrouter_gemini(prompt_text: str) -> str:
    """
    Faz uma chamada √† API do OpenRouter usando o modelo Gemini para gerar texto.
    """
    openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
    if not openrouter_api_key:
        raise ValueError("OPENROUTER_API_KEY n√£o configurada no arquivo .env")

    # O modelo Gemini no OpenRouter geralmente espera um formato de mensagem espec√≠fico.
    # Para gera√ß√£o de texto simples, um √∫nico role 'user' com o conte√∫do √© suficiente.
    # O modelo "google/gemini-2.0-flash-exp:free" que voc√™ mencionou √© um modelo experimental
    # e pode ter sido renomeado ou descontinuado.
    # Recomendo usar "google/gemini-pro" ou "google/gemini-1.5-flash" para estabilidade.
    # Verifique a lista de modelos no site do OpenRouter.
    model_name = os.getenv("OPENROUTER_MODEL_NAME", "google/gemini-1.5-flash") # Modelo padr√£o

    headers = {
        "Authorization": f"Bearer {openrouter_api_key}",
        "Content-Type": "application/json"
    }

    # O formato de mensagens para a API de chat √© uma lista de dicion√°rios.
    # Cada dicion√°rio tem um 'role' (user, assistant, system) e 'content'.
    # Para o seu caso, o 'content' √© o prompt do usu√°rio.
    data = json.dumps({
        "model": model_name,
        "messages": [
            {"role": "user", "content": prompt_text}
        ]
    })

    try:
        response = requests.post(
            url="https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            data=data
         )
        response.raise_for_status() # Levanta um erro para c√≥digos de status HTTP ruins (4xx ou 5xx)
        response_json = response.json()

        # A resposta da API do OpenRouter (e OpenAI-like) para chat completions
        # geralmente tem o texto gerado em response_json['choices'][0]['message']['content']
        if response_json and response_json.get('choices') and response_json['choices'][0].get('message'):
            return response_json['choices'][0]['message']['content']
        else:
            return "N√£o foi poss√≠vel obter uma resposta do modelo."

    except requests.exceptions.RequestException as e:
        st.error(f"Erro de conex√£o com a API do OpenRouter: {e}")
        return f"Erro de conex√£o: {e}"
    except json.JSONDecodeError:
        st.error("Erro ao decodificar a resposta JSON da API do OpenRouter.")
        return "Erro ao processar a resposta da API."
    except Exception as e:
        st.error(f"Ocorreu um erro inesperado ao chamar o OpenRouter: {e}")
        return f"Erro inesperado: {e}"

# N√£o precisamos mais de openrouter_llm como um objeto global se n√£o estamos usando CrewAI.
# A fun√ß√£o call_openrouter_gemini ser√° chamada diretamente.

# --- Interface do Usu√°rio ---
st.header("Descreva a Infraestrutura Desejada")

prompt = st.text_area(
    "Forne√ßa um prompt claro e detalhado. Quanto mais espec√≠fico voc√™ for, melhor ser√° o resultado.",
    height=150,
    placeholder="Exemplo: Crie o c√≥digo IaC com Terraform para criar um bucket S3 na AWS com o nome 'dsa-bucket-super-seguro-12345', com versionamento e criptografia SSE-S3 habilitados."
)

# O bot√£o estar√° sempre habilitado, mas a chamada √† API s√≥ ocorrer√° se a chave estiver presente.
if st.button("Gerar Script Terraform", type="primary"):
    if prompt:
        # Verifica se a chave API est√° configurada antes de tentar chamar a fun√ß√£o
        if not os.getenv("OPENROUTER_API_KEY"):
            st.error("OPENROUTER_API_KEY n√£o configurada no arquivo .env. Por favor, configure-a.")
        else:
            with st.spinner("O Agente de IA est√° trabalhando... Pratique a paci√™ncia e aguarde."):
                try:
                    # A "tarefa" agora √© simplesmente chamar a fun√ß√£o que interage com o OpenRouter
                    # e passar o prompt do usu√°rio diretamente.
                    # Voc√™ pode adicionar instru√ß√µes adicionais ao prompt aqui, se desejar,
                    # para guiar o Gemini a gerar apenas o c√≥digo HCL.
                    full_prompt = (
                        f"Com base na seguinte solicita√ß√£o do usu√°rio, gere um script Terraform completo e funcional. "
                        f"A sa√≠da deve ser APENAS o bloco de c√≥digo HCL, sem nenhuma explica√ß√£o ou texto adicional. "
                        f"O c√≥digo deve ser bem formatado e pronto para ser salvo em um arquivo .tf.\n\n"
                        f"Solicita√ß√£o do Usu√°rio: '{prompt}'"
                    )
                    result = call_openrouter_gemini(full_prompt)

                    # Exibe o resultado
                    st.header("Resultado Gerado")
                    st.code(result, language='terraform')
                    st.success("Script gerado com sucesso! Obrigado DSA.")

                except Exception as e:
                    st.error(f"Ocorreu um erro durante a execu√ß√£o: {e}")
    else:
        st.warning("Por favor, insira uma descri√ß√£o da infraestrutura para gerar o script.")

st.markdown("---")
st.markdown("Constru√≠do com [Streamlit](https://streamlit.io/ ) na [Data Science Academy](https://www.datascienceacademy.com.br/ )")
